Atelier : Impl√©menter une Architecture Lambda simplifi√©e avec Spark et Kafka
R√©alis√© par

üë©‚Äçüíª Hajar Elfallaki-Idrissi

üìå Table des mati√®res

Introduction

Objectifs p√©dagogiques

Rappel th√©orique : Architecture Lambda

Pr√©-requis techniques

Structure du projet

Dataset utilis√©

Mise en place de l‚Äôenvironnement (Docker)

Batch Layer ‚Äì Traitement des donn√©es historiques

Speed Layer ‚Äì Traitement en temps r√©el

Serving Layer ‚Äì Fusion Batch + Streaming

Captures d‚Äô√©cran

Questions et r√©ponses

Conclusion

Introduction

Cet atelier a pour objectif de guider les √©tudiants dans la mise en place d‚Äôune architecture Lambda simplifi√©e afin de comprendre les principes fondamentaux du traitement de donn√©es Big Data, √† la fois en mode batch et en mode streaming gr√¢ce √† Spark et Kafka.

Objectifs p√©dagogiques

√Ä la fin de cet atelier, les √©tudiants seront capables de :

Expliquer les couches : Batch Layer, Speed Layer, Serving Layer

Impl√©menter un traitement batch avec Spark

Impl√©menter un traitement streaming avec Spark Structured Streaming

Utiliser Kafka comme source temps r√©el

Fusionner les r√©sultats batch & streaming

Comprendre les limites de l'architecture Lambda

Rappel th√©orique : Architecture Lambda
1) Batch Layer

Traite toutes les donn√©es historiques

Produit des r√©sultats pr√©cis (batch views)

Exemple : Spark Batch ou Hadoop MapReduce

2) Speed Layer (Streaming Layer)

Traite les nouvelles donn√©es en temps r√©el

Produit des r√©sultats rapides mais approximatifs

Exemple : Kafka + Spark Structured Streaming ou Flink

3) Serving Layer

Combine les r√©sultats de Batch & Speed Layer

Fournit une vue finale aux applications clientes

Pr√©-requis techniques

Bases sur Spark (DataFrames, spark-submit)

Bases sur Kafka (topics, producteurs)

Docker et Docker Compose install√©s

Structure du projet
atelier-lambda/
‚îÇ docker-compose.yml
‚îÇ
‚îî‚îÄ‚îÄ‚îÄapp/
    ‚îÇ batch_job.py
    ‚îÇ streaming_job.py
    ‚îÇ serving_layer.py
    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄdatasets/
           transactions.json

Dataset utilis√©

app/datasets/transactions.json

{"customer": "Ali", "amount": 120}
{"customer": "Sara", "amount": 90}
{"customer": "Ali", "amount": 200}
{"customer": "Mounir", "amount": 150}
{"customer": "Sara", "amount": 50}

Mise en place de l‚Äôenvironnement (Docker)

D√©marrer la stack :

docker compose up -d


V√©rifier :

docker ps

Batch Layer ‚Äì Traitement des donn√©es historiques

Script : app/batch_job.py

Ex√©cution :

docker exec -it spark spark-submit /app/batch_job.py


Objectif p√©dagogique : comprendre le r√¥le de la Batch Layer et produire une vue agr√©g√©e des donn√©es historiques.

Speed Layer ‚Äì Traitement en temps r√©el
1. Cr√©ation du topic Kafka
docker exec -it kafka kafka-topics.sh \
--create --topic real-time-orders \
--bootstrap-server kafka:9092

2. Producteur Kafka
docker exec -it kafka kafka-console-producer.sh \
--topic real-time-orders \
--bootstrap-server kafka:9092


Exemples de messages JSON :

{"customer":"Ali","amount":80}
{"customer":"Mounir","amount":200}
{"customer":"Sara","amount":40}

3. Lancer le streaming :
docker exec -it spark spark-submit /app/streaming_job.py


Objectif p√©dagogique : visualiser les agr√©gations en temps r√©el et comprendre la Speed Layer.

Serving Layer ‚Äì Fusion Batch + Streaming

Script : app/serving_layer.py

Ex√©cution :

docker exec -it spark python /app/serving_layer.py


Objectif : combiner les r√©sultats batch et streaming pour produire la Serving View finale.

Captures d‚Äô√©cran

üì∏ Capture 1 ‚Äî Conteneurs Docker actifs

(Ins√©rer ici la capture d‚Äô√©cran de docker ps)

üì∏ Capture 2 ‚Äî R√©sultat du batch job

(Ins√©rer ici la capture d‚Äô√©cran de l‚Äôagr√©gation batch)

üì∏ Capture 3 ‚Äî Producteur Kafka avec messages JSON

(Ins√©rer ici la capture d‚Äô√©cran)

üì∏ Capture 4 ‚Äî Spark Streaming en temps r√©el

(Ins√©rer ici la capture d‚Äô√©cran du streaming)

üì∏ Capture 5 ‚Äî R√©sultat final serving_view.json

(Ins√©rer ici la capture d‚Äô√©cran du JSON final)

Questions et r√©ponses

1. R√¥le de chaque couche

Batch Layer : traite tout l‚Äôhistorique, r√©sultats exacts

Speed Layer : traite en temps r√©el, r√©sultats approximatifs

Serving Layer : combine batch + streaming, fournit vue finale

2. Modifier batch_job.py pour clients avec somme > 200

GroupBy customer, somme amount, filter total_amount > 200

3. Modifier streaming_job.py pour transactions amount >= 100

Lire le flux Kafka, filter amount >= 100

4. Adapter serving_layer.py pour √©crire serving_view.json

Fusionner batch + streaming, write JSON mode overwrite

5. Limites de l‚Äôarchitecture Lambda

Double code entre batch et streaming

Complexit√© de maintenance

Risque d‚Äôincoh√©rence

Infrastructure lourde

Scalabilit√© difficile

6. Motivation de l‚Äôarchitecture Kappa

Supprime Batch Layer

Pipeline streaming unique

Moins de maintenance, moins de co√ªts

Traitement unifi√© historique + temps r√©el

Conclusion

Cet atelier permet de comprendre et exp√©rimenter l‚Äôarchitecture Lambda en utilisant Spark et Kafka, tout en visualisant la diff√©rence entre traitement batch et streaming, et la fusion des r√©sultats dans une Serving Layer. Il met en √©vidence les avantages et limites de l‚Äôarchitecture Lambda, et pr√©pare √† des architectures plus modernes comme Kappa.
