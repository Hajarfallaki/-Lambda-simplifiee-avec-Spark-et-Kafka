# ğŸš€ Architecture Lambda avec Spark et Kafka

> Atelier pratique pour implÃ©menter une architecture Lambda simplifiÃ©e

**RÃ©alisÃ© par** : ğŸ‘©â€ğŸ’» Hajar Elfallaki-Idrissi

---

## ğŸ“‹ Table des matiÃ¨res

- [Introduction](#introduction)
- [Objectifs pÃ©dagogiques](#objectifs-pÃ©dagogiques)
- [Architecture Lambda - Rappel thÃ©orique](#architecture-lambda---rappel-thÃ©orique)
- [PrÃ©-requis techniques](#prÃ©-requis-techniques)
- [Structure du projet](#structure-du-projet)
- [Dataset utilisÃ©](#dataset-utilisÃ©)
- [Installation et dÃ©marrage](#installation-et-dÃ©marrage)
- [Batch Layer](#batch-layer--traitement-des-donnÃ©es-historiques)
- [Speed Layer](#speed-layer--traitement-en-temps-rÃ©el)
- [Serving Layer](#serving-layer--fusion-batch--streaming)
- [Code source](#code-source)
- [Captures d'Ã©cran](#captures-dÃ©cran)
- [Questions et rÃ©ponses](#questions-et-rÃ©ponses)
- [Conclusion](#conclusion)

---

## ğŸ¯ Introduction

Cet atelier guide les Ã©tudiants dans la mise en place d'une **architecture Lambda simplifiÃ©e** pour comprendre les principes fondamentaux du traitement de donnÃ©es Big Data, Ã  la fois en mode **batch** et en mode **streaming** grÃ¢ce Ã  **Apache Spark** et **Apache Kafka**.

---

## ğŸ“š Objectifs pÃ©dagogiques

Ã€ la fin de cet atelier, vous serez capable de :

âœ… Expliquer les trois couches de l'architecture Lambda : **Batch Layer**, **Speed Layer**, **Serving Layer**  
âœ… ImplÃ©menter un traitement batch avec **Spark**  
âœ… ImplÃ©menter un traitement streaming avec **Spark Structured Streaming**  
âœ… Utiliser **Kafka** comme source temps rÃ©el  
âœ… Fusionner les rÃ©sultats batch & streaming  
âœ… Comprendre les limites de l'architecture Lambda  

---

## ğŸ—ï¸ Architecture Lambda - Rappel thÃ©orique

### 1ï¸âƒ£ Batch Layer
- **RÃ´le** : Traite toutes les donnÃ©es historiques
- **RÃ©sultat** : Vues batch prÃ©cises et complÃ¨tes
- **Technologies** : Spark Batch, Hadoop MapReduce

### 2ï¸âƒ£ Speed Layer (Streaming Layer)
- **RÃ´le** : Traite les nouvelles donnÃ©es en temps rÃ©el
- **RÃ©sultat** : RÃ©sultats rapides mais approximatifs
- **Technologies** : Kafka + Spark Structured Streaming, Apache Flink

### 3ï¸âƒ£ Serving Layer
- **RÃ´le** : Combine les rÃ©sultats de Batch & Speed Layer
- **RÃ©sultat** : Vue finale unifiÃ©e pour les applications clientes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ARCHITECTURE LAMBDA                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  DonnÃ©es historiques          Nouvelles donnÃ©es (temps rÃ©el)
         â”‚                              â”‚
         â–¼                              â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Batch    â”‚                 â”‚    Speed     â”‚
   â”‚  Layer    â”‚                 â”‚    Layer     â”‚
   â”‚  (Spark)  â”‚                 â”‚(Kafka+Spark) â”‚
   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                              â”‚
         â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Serving    â”‚â—€â”€â”€â”€â”€â”˜
                   â”‚    Layer     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                   Applications clientes
```

---

## âš™ï¸ PrÃ©-requis techniques

- ğŸ³ **Docker** et **Docker Compose** installÃ©s
- ğŸ Connaissances de base en **Python**
- âš¡ Notions sur **Apache Spark** (DataFrames, spark-submit)
- ğŸ“¨ Notions sur **Apache Kafka** (topics, producteurs)

---

## ğŸ“ Structure du projet

```
atelier-lambda/
â”‚
â”œâ”€â”€ docker-compose.yml          # Configuration Docker (Spark + Kafka + Zookeeper)
â”‚
â””â”€â”€ app/
    â”œâ”€â”€ batch_job.py            # Script Batch Layer
    â”œâ”€â”€ streaming_job.py        # Script Speed Layer
    â”œâ”€â”€ serving_layer.py        # Script Serving Layer
    â”‚
    â””â”€â”€ datasets/
        â””â”€â”€ transactions.json   # DonnÃ©es historiques
```

---

## ğŸ“Š Dataset utilisÃ©

**Fichier** : `app/datasets/transactions.json`

```json
{"customer": "Ali", "amount": 120}
{"customer": "Sara", "amount": 90}
{"customer": "Ali", "amount": 200}
{"customer": "Mounir", "amount": 150}
{"customer": "Sara", "amount": 50}
```

---

## ğŸ³ Installation et dÃ©marrage

### 1. Cloner le projet

```bash
git clone <url-du-repo>
cd atelier-lambda
```

### 2. CrÃ©er le fichier `docker-compose.yml`

```yaml
version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  spark:
    image: bitnami/spark:3.5
    container_name: spark
    environment:
      - SPARK_MODE=master
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./app:/app
```

### 3. DÃ©marrer les services

```bash
docker compose up -d
```

### 4. VÃ©rifier que les conteneurs sont actifs

```bash
docker ps
```

Vous devriez voir : `zookeeper`, `kafka`, `spark`

---

## ğŸ—‚ï¸ Batch Layer â€“ Traitement des donnÃ©es historiques

### Objectif
Traiter l'ensemble des donnÃ©es historiques et produire une vue agrÃ©gÃ©e par client.

### Script : `app/batch_job.py`

```python
from pyspark.sql import SparkSession

# Initialiser Spark
spark = SparkSession.builder \
    .appName("BatchLayer") \
    .getOrCreate()

# Lire les donnÃ©es historiques
df = spark.read.json("/app/datasets/transactions.json")

# AgrÃ©ger par client
batch_view = df.groupBy("customer").sum("amount") \
    .withColumnRenamed("sum(amount)", "total_amount")

# Afficher le rÃ©sultat
batch_view.show()

# Sauvegarder le rÃ©sultat
batch_view.write.mode("overwrite").json("/app/output/batch_view")

spark.stop()
```

### ExÃ©cution

```bash
docker exec -it spark spark-submit /app/batch_job.py
```

### RÃ©sultat attendu

```
+--------+------------+
|customer|total_amount|
+--------+------------+
|Ali     |320         |
|Sara    |140         |
|Mounir  |150         |
+--------+------------+
```

---

## âš¡ Speed Layer â€“ Traitement en temps rÃ©el

### Objectif
Traiter les nouvelles transactions en temps rÃ©el via Kafka et Spark Streaming.

### 1. CrÃ©er le topic Kafka

```bash
docker exec -it kafka kafka-topics.sh \
  --create --topic real-time-orders \
  --bootstrap-server kafka:9092
```

### 2. Script : `app/streaming_job.py`

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, sum as _sum

# Initialiser Spark avec support Kafka
spark = SparkSession.builder \
    .appName("SpeedLayer") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0") \
    .getOrCreate()

# Lire le flux Kafka
df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "kafka:9092") \
    .option("subscribe", "real-time-orders") \
    .load()

# Parser les donnÃ©es JSON
from pyspark.sql.types import StructType, StructField, StringType, IntegerType

schema = StructType([
    StructField("customer", StringType(), True),
    StructField("amount", IntegerType(), True)
])

parsed_df = df.selectExpr("CAST(value AS STRING)") \
    .select(from_json(col("value"), schema).alias("data")) \
    .select("data.*")

# AgrÃ©ger en temps rÃ©el
streaming_view = parsed_df.groupBy("customer").agg(_sum("amount").alias("total_amount"))

# Afficher les rÃ©sultats en continu
query = streaming_view.writeStream \
    .outputMode("complete") \
    .format("console") \
    .start()

query.awaitTermination()
```

### 3. Lancer le streaming job

```bash
docker exec -it spark spark-submit /app/streaming_job.py
```

### 4. Envoyer des messages au producteur Kafka

```bash
docker exec -it kafka kafka-console-producer.sh \
  --topic real-time-orders \
  --bootstrap-server kafka:9092
```

Saisir les messages suivants :

```json
{"customer":"Ali","amount":80}
{"customer":"Mounir","amount":200}
{"customer":"Sara","amount":40}
```

### RÃ©sultat en temps rÃ©el

Les agrÃ©gations s'affichent en continu dans la console Spark.

---

## ğŸ”„ Serving Layer â€“ Fusion Batch + Streaming

### Objectif
Combiner les rÃ©sultats du batch et du streaming pour produire une vue finale unifiÃ©e.

### Script : `app/serving_layer.py`

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("ServingLayer") \
    .getOrCreate()

# Charger la vue batch
batch_view = spark.read.json("/app/output/batch_view")

# Charger la vue streaming (simulÃ©e ici via un fichier)
streaming_view = spark.read.json("/app/output/streaming_view")

# Fusionner les deux vues
serving_view = batch_view.union(streaming_view) \
    .groupBy("customer").sum("total_amount") \
    .withColumnRenamed("sum(total_amount)", "final_amount")

# Afficher le rÃ©sultat
serving_view.show()

# Sauvegarder la vue finale
serving_view.write.mode("overwrite").json("/app/output/serving_view.json")

spark.stop()
```

### ExÃ©cution

```bash
docker exec -it spark python /app/serving_layer.py
```

### RÃ©sultat final

```
+--------+------------+
|customer|final_amount|
+--------+------------+
|Ali     |400         |
|Sara    |180         |
|Mounir  |350         |
+--------+------------+
```

---

## ğŸ“¸ Captures d'Ã©cran

### ğŸ“¸ Capture 1 â€” Conteneurs Docker actifs
*(InsÃ©rer ici la capture d'Ã©cran de `docker ps`)*

### ğŸ“¸ Capture 2 â€” RÃ©sultat du batch job
*(InsÃ©rer ici la capture d'Ã©cran de l'agrÃ©gation batch)*

### ğŸ“¸ Capture 3 â€” Producteur Kafka avec messages JSON
*(InsÃ©rer ici la capture d'Ã©cran)*

### ğŸ“¸ Capture 4 â€” Spark Streaming en temps rÃ©el
*(InsÃ©rer ici la capture d'Ã©cran du streaming)*

### ğŸ“¸ Capture 5 â€” RÃ©sultat final `serving_view.json`
*(InsÃ©rer ici la capture d'Ã©cran du JSON final)*

---

## â“ Questions et rÃ©ponses

### 1. Quel est le rÃ´le de chaque couche ?

- **Batch Layer** : Traite tout l'historique, produit des rÃ©sultats exacts
- **Speed Layer** : Traite en temps rÃ©el, rÃ©sultats rapides mais approximatifs
- **Serving Layer** : Combine batch + streaming, fournit la vue finale

### 2. Comment modifier `batch_job.py` pour ne garder que les clients avec une somme > 200 ?

```python
batch_view = df.groupBy("customer").sum("amount") \
    .withColumnRenamed("sum(amount)", "total_amount") \
    .filter(col("total_amount") > 200)
```

### 3. Comment modifier `streaming_job.py` pour filtrer les transactions >= 100 ?

```python
parsed_df = parsed_df.filter(col("amount") >= 100)
```

### 4. Comment adapter `serving_layer.py` pour Ã©crire `serving_view.json` ?

```python
serving_view.write.mode("overwrite").json("/app/output/serving_view.json")
```

### 5. Quelles sont les limites de l'architecture Lambda ?

âŒ **Double code** entre batch et streaming  
âŒ **ComplexitÃ© de maintenance**  
âŒ **Risque d'incohÃ©rence** entre les deux couches  
âŒ **Infrastructure lourde** (gestion de deux pipelines)  
âŒ **ScalabilitÃ© difficile**  

### 6. Quelle est la motivation de l'architecture Kappa ?

âœ… Supprime la Batch Layer  
âœ… Pipeline streaming unique  
âœ… Moins de maintenance, coÃ»ts rÃ©duits  
âœ… Traitement unifiÃ© historique + temps rÃ©el  

---

## ğŸ“ Conclusion

Cet atelier permet de comprendre et expÃ©rimenter l'**architecture Lambda** en utilisant **Apache Spark** et **Apache Kafka**, tout en visualisant la diffÃ©rence entre traitement batch et streaming, et la fusion des rÃ©sultats dans une Serving Layer.

Il met en Ã©vidence les **avantages** et **limites** de l'architecture Lambda, et prÃ©pare Ã  des architectures plus modernes comme **Kappa**.

---

## ğŸ“ Licence

Ce projet est Ã  usage pÃ©dagogique.

---

**Bon courage ! ğŸš€**
